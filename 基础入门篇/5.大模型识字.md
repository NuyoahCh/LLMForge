我们人类看到的是文字，大脑会把这个文字的这个视觉信号转换成生物电信号来处理。



推荐视频：[https://www.bilibili.com/video/BV1bfoQYCEHC?t=288.1](https://www.bilibili.com/video/BV1bfoQYCEHC?t=288.1)



那大模型怎么识字呢？或者更正式一点的说法是如何表示文字，让大模型能识别？



一个最简单的方法就是编码(encode)，每一个文字给一点个特定的编号。假设有一个词表(vocabulary)，词表中的每个文字都有一个独立的编号的话，模型就可以区分到底是哪一个文字。比如：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761044143283-aeabdcf5-8f57-4be0-bb3a-613fdf9dfcd6.png)



在上面的词表中，词表中的每个词被称为 token，每个 token 都有一个 token id。



看上面的词表，“模型”两个字被当成了一个 token，这是因为对于一些常用的词语，在构建词表的时候可以合并成一个 token。这样一个 token 就可以表示两个字，提高了大模型的处理速度。



所以构建词表是大模型识字的前提，而如何构造词表，则决定了大模型的识字效率。至于如何高效的构建词表，是有不同的算法实现的，这些算法我们下一节再讲。因为有不同的算法实现了不同的构建词表的方式，所以我们需要使用对应的方法将文字转换成该词表对应的token，这个工作由 tokenizer 来完成。如下图：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761044178916-968fb89f-9182-460d-b1cb-e67059e10c2c.png)



不同的模型使用的 tokenizer 很可能是不一样的，这一点一定要注意。



到目前为止，大模型通过 tokenizer 可以将文字转换为token id，但是每个 token id的含义怎么表示呢？就像我们身份证上除了身份证号以外，还要有一些别的信息来展示一个人的身份信息一样，每一个 token id 也可以给一些表明身份的信息，这个信息在大模型中用向量来表示，被称为 Embedding。



使用向量来表示特征在机器学习中早就有大规模的使用，可以认为向量中的每一维都代表了一个特征。比如有一个向量有三个值，分别代表了性别（1表示男，0表示女），年龄，是否阅读了本书（1表示阅读过，0表示没有），那么 [0, 25, 0] 就代表了一个25岁没有读过本书的女生。

这就是 one-hot 的向量。



而大模型中 Embedding 的含义通常是不太好解释的，因为Embedding 的长度是有限的，而要学习的特征数量可能远远超过 Embedding 的长度，所以没有办法做到像 one-hot 那样一维代表一个特征。



此时每一维代表的特征可能是一个高维空间特征值的映射，就类似对一个高维矩阵做了 SVD 分解。

所以大模型如何理解文本数据就有两个要解决的问题。一个是如何将一个文本序列拆分成 token 的序列，一个是如何得到每个 token 的 Embedding。



关于如何得到每一个 token 的 Embedding，通常有两种方式：

专门训练 Embedding，比如早期的 Word2vec，Glove ，比较新的 BGE 等。这些训练出来的 Embedding 通常用于一些向量检索方面的任务。



关于 Embedding 的一些原理，可以先从 word2vec 开始了解。

Embedding 的权重作为模型权重的一部分，当模型训练完成，也就得到了一份 Embedding。这些Embedding 通常不能直接用来做向量检索，因为大模型的训练目标通常是下一个词是什么，而不是语义的相似度。



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761044179163-b77ebd39-34fb-4079-92f6-bf44689451b5.png)



大模型的 Embedding主要采用第二种方法来获取。如图，网络结构中有一个专门的 Embedding 层。

