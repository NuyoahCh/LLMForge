项目地址：[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)

![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761062665619-5422bb17-1074-42e5-ae8f-8158126b12cc.png)



<h1 id="XmqMM">介绍LangChain</h1>
<h2 id="EztV6">什么是LangChain</h2>
LangChain是 2022年10月 ，由哈佛大学的 Harrison Chase (哈里森·蔡斯)发起研发的一个开源框架， 用于开发由大语言模型(LLMs)驱动的应用程序。 



比如，搭建“智能体”(Agent)、问答系统(QA)、对话机器人、文档搜索系统、企业私有知识库等。 



官方解释：

LangChain is a framework for building LLM-powered applications. It helps you chain together interoperable components and third-party integrations to simplify AI application development — all while future-proofing decisions as the underlying technology evolves.



热度变化：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761062838890-2f09b123-b2a9-4518-a095-befb8195720e.png)<font style="background-color:rgb(100.000000%, 100.000000%, 100.000000%);">			</font>

简单概括：		

LangChain ≠ LLMs

LangChain 之于 LLMs，类似 Spring 之于 Java 

LangChain 之于 LLMs，类似 Django、Flask 之于 Python 



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761062967397-35cf582c-bf79-4063-b01c-a0ba1148af68.png)



学习LangChain框架，高效开发大模型应用。



<h2 id="ZTiUx">大模型应用开发框架列举</h2>
![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761063064736-3812f018-ea89-4019-8228-f606965a3b1b.png)



LangChain：这些工具中出现最早、最成熟、适合复杂任务分解和单智能应用。

LlamaIndex：专注高效的索引和检索，适合 RAG 场景。

LangChain4J：LangChain 的 Java 版本，核心功能存在，整体上略少于 LangChain。

SpringAI/SpringAI Alibaba：有待进一步成熟，此外对接口进行封装。

SemanticKernel：微软推出，C# 独享。



没有绝对的好与坏的模型，而是在合适的业务场景，选择最合适的模型，进行实践和落地。



<h2 id="aLBpQ">为什么需要LangChain</h2>
不使用LangChain，确实可以使用GPT 或GLM4 等模型的API进行开发。比如，搭建“智能体” (Agent)、问答系统、对话机器人等复杂的 LLM 应用。 



但是 LangChain 的好处如下：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761111532655-df526139-9dba-45d1-a7f6-644b21bdf982.png)



这个地方可以使用 LangChain 和 JDBC 进行类比：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761111560743-9c471e02-5b16-438c-b34c-d5f50d2814f7.png)



这就是想要说明，当然，我们不去使用这样的大模型框架也是可以的，但是如果我们每一个模型都要去产生一个 API 进行对应的话，那么实在是太复杂了，所以我们完全可以通过加一个中间层的思想，在本质上简化我们的开发。



LangChain 是一个帮助你构建 LLM 应用的 全套工具集。这里涉及到prompt 构建、LLM 接入、记忆管理、工具调用、RAG、智能体开发等模块。



学习 LangChain 最好的方式就是做项目。



<h2 id="q0x6w">LangChain的使用场景</h2>


![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761111685942-88fe3836-d933-427b-99ca-64e6cb9e8e28.png)



<h2 id="GPM2p">架构设计</h2>
<h3 id="O5C0y">V0.1 版本</h3>
![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761111725140-1883b61e-2edf-4c0f-a01a-e6733b580a6b.png)



<h3 id="jUpDJ">V0.2 / V0.3 版本</h3>
![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761111747518-d25ad9a8-6171-4fac-8346-79b574936005.png)



版本的升级，v0.2 相较于v0.1，修改了大概10%-15%。功能性上差不多，主要是往稳定性（或兼容性）、安全性上使劲了，支持更多的大模型，更安全。



<h1 id="aZVYV">开发环境准备</h1>
笔者使用的 MacBookPro，通过 MiniConda 的方式进行环境的搭建，这里不再过多的赘述，还存在问题，可以自行 Google 进行解决。



<h1 id="DtEUS">大模型应用开发</h1>
大模型应用技术特点：门槛低，天花板高。



<h2 id="WUAaN">基于RAG架构的开发</h2>
背景：

+ 大模型的知识冻结
+ 大模型幻觉



而RAG就可以非常精准的解决这两个问题。



举例：

LLM在考试的时候面对陌生的领域，答复能力有限，然后就准备放飞自我了。而此时RAG给了一些提示和思路，让LLM懂了开始往这个提示的方向做，最终考试的正确率从60%到了90%！



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120266212-c2ec6a38-d0eb-4cd9-b314-b54487d737f4.png)



何为RAG：

Retrieval-Augmented Generation（检索增强生成）



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120355162-a88e22dc-08e6-4f81-8dee-efb0fb11de38.png)



检索-增强-生成过程：检索可以理解为第10步，增强理解为第12步（这里的提示词包含检索到的数据），生成理解为第15步。



类似的细节图：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120425042-08caecb2-463f-4846-8777-cf4a98e82e04.png)



强调一下难点的步骤：



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120486729-1c3e2c56-b49d-4b53-90ec-0b4e094493fd.png)



Reranker的使用场景：

+ 适合：追求回答高精度和高相关性的场景中特别适合使用 Reranker，例如专业知识库或者客服系统等应用。
+ 不适合：引入reranker会增加召回时间，增加检索延迟。服务对 响应时间要求高时，使用reranker可能不合适。



这里有三个位置涉及到大模型的使用：

+ 第3步向量化时，需要使用EmbeddingModels。
+ 第7步重排序时，需要使用RerankModels。
+ 第9步生成答案时，需要使用LLM。



<h2 id="AloLh">基于Agent架构的开发</h2>
充分利用 LLM 的推理决策能力，通过增加 规划、记忆 和 工具 调用的能力，构造一个能够独立思考、逐步完成给定目标的智能体。



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120720345-c16168f2-e518-4fca-87c0-d06c3674d129.png)



举例：传统的程序 vs Agent（智能体）



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120756490-a93214de-164d-4f51-8a8f-ba135efb29b4.png)



Agent 架构。



一个数学公式来表示：

Agent = LLM + Memory + Tools + Planning + Action



![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761120801767-4423795e-1663-4883-8a6d-7f5af0389eff.png)







