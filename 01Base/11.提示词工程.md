<h1 id="c7oAd">什么是提示工程</h1>
提示工程是指导[生成式人工智能（生成式 AI）](https://aws.amazon.com/what-is/generative-ai/)解决方案生成所需输出的过程。尽管生成式人工智能试图模仿人类，但需要详细的说明才能创建高质量和相关的输出。在提示工程中，您可以选择最合适的格式、短语、单词和符号，以指导 AI 与用户进行更有意义的交互。提示工程师利用创造力加上试错来创建输入文本的集合，因此应用程序的生成式人工智能可以按预期工作。



<h2 id="seo-faq-pairs#what-is-a-prompt">什么是提示</h2>
提示是一种自然语言文本，要求[生成式人工智能](https://aws.amazon.com/ai/generative-ai/)执行特定任务。生成式人工智能是一种人工智能解决方案，可以创建故事、对话、视频、图像和音乐等新内容。由超大型机器学习（ML）模型提供支持，这些模型使用已针对大量数据进行预训练的深度神经网络。

大型语言模型（LLM）非常灵活，可以执行各种任务。例如，可以总结文档、补全句子、回答问题和翻译语言。对于特定的用户输入，模型会通过过去的训练预测其认为最佳的输出。

但是，由于这些模型非常开放，因此您的用户可以通过无数的输入数据组合与生成式人工智能解决方案进行交互。人工智能语言模型非常强大，无需太多输入即可开始创建内容。即使是一个单词也足以让系统做出详细的回应。

话虽如此，并非每种类型的输入都能产生有用的输出。生成式人工智能系统需要背景和详细信息才能生成准确和相关的响应。当您系统地设计提示时，就会得到更有意义和更实用的作品。在即时工程中，您可以不断完善提示，直到从人工智能系统中获得所需的结果。

[阅读有关生成式人工智能的信息 »](https://aws.amazon.com/what-is/generative-ai/)

[阅读有关大型语言模型（LLM）的信息 »](https://aws.amazon.com/what-is/large-language-model/)



<h2 id="seo-faq-pairs#why-is-prompt-engineering-important">为什么提示工程很重要</h2>
自生成式人工智能推出以来，即时工程工作岗位大幅增加。提示工程师弥合了最终用户和大型语言模型之间的差距。他们可以确定用户可以自定义和完成的脚本和模板，以便通过语言模型获得最佳结果。这些工程师尝试使用不同类型的输入来构建提示库，以便应用程序开发人员在不同的场景中重复使用。

提示工程使 AI 应用程序更加高效和有效。应用程序开发人员通常会将开放式用户输入封装在提示中，然后再将其传递给 AI 模型。

例如，假设有一个 AI [聊天机器人](https://aws.amazon.com/what-is/chatbot/)。用户可能会输入不完整的问题陈述，例如“去哪里购买衬衫？” 在内部，该应用程序的代码使用工程提示“您是一家服装公司的销售助理。一位居住在美国阿拉巴马州的用户询问在哪里可以买到衬衫。请回复目前有衬衫的最近三家门店。” 然后，聊天机器人会生成更相关、更准确的信息。

接下来，我们将讨论提示工程的一些好处。



<h3 id="e9ee6a9a">更强的开发人员控制力</h3>
通过提示工程，开发人员能够更好地控制用户与 AI 的互动。有效的提示可以为大型语言模型提供意图并建立上下文。可以帮助 AI 完善输出，并以所需的格式简洁地呈现出来。

还可以防止您的用户滥用 AI 或请求 AI 不知道或无法准确处理的内容。例如，您可能希望限制用户在商业 AI 应用程序中生成不当内容。



<h3 id="7635264d">改善用户体验</h3>
用户可以避免反复试验，同时仍然可以通过 AI 工具获得连贯、准确和相关的响应。提示工程使用户可以轻松地在第一个提示中获得相关结果，有助于减轻大型语言模型训练数据中现有的人为偏见。

此外，提示工程还增强了用户-AI 的互动，使 AI 能通过最少的输入理解用户的意图。例如，对法律文件和新闻报道进行总结的请求可以获得不同风格和语气的不同结果。即使两个用户对应用程序的指示都是“总结一下这份文档”，也是如此。



<h3 id="27df2a8b">更高的灵活性</h3>
更高的抽象级别可以改进 AI 模型，并允许组织大规模创建更灵活的工具。提示工程师可以通过与域无关的指令创建提示，突出显示逻辑链接和广泛模式。组织可以在整个企业中快速重复使用这些提示，以扩大其 AI 投资。

例如，为了寻找流程优化的机会，提示工程师可以创建不同的提示，训练 AI 模型使用广泛的信号而不是特定于上下文的数据来发现效率低下的问题。然后，可以将这些提示用于不同的流程和业务部门。



<h2 id="seo-faq-pairs#what-are-some-prompt-engineering-use-cases">有哪些提示工程使用案例</h2>
提示工程技术可用于复杂的 AI 系统，以改善学习语言模型的用户体验。下面是一些示例。



<h3 id="ea057a90">主题专业知识</h3>
提示工程在需要 AI 以主题专业知识做出响应的应用中发挥着关键作用。具有该领域经验的提示工程师可以引导 AI 引用正确的来源，并根据提出的问题正确构思答案。

例如，在医学领域，医生可以使用提示工程语言模型为复杂病例生成鉴别诊断。医疗专业人员只需要输入症状和患者详细信息即可。该应用使用精心设计的提示来引导 AI 首先列出与输入的症状相关的可能疾病。然后，根据其他患者信息缩小列表范围。



<h3 id="95874e22">批判性思维</h3>
批判性思维应用需要语言模型来解决复杂的问题。为此，模型将从不同角度分析信息，评估其可信度，并做出合理的决定。提示工程增强了模型的数据分析能力。

例如，在决策场景中，您可以提示模型列出所有可能的选项，评估每个选项，并推荐最佳解决方案。



<h3 id="18d1d095">创造力</h3>
创造力涉及产生新的想法、概念或解决方案。提示工程可用于增强模型在各种场景中的创造能力。

例如，在写作场景中，作家可以使用提示工程模型来帮助构思故事。作者可以提示模型列出可能的角色、设置和情节，然后用这些元素形成一个故事。或者，平面设计师可以提示模型生成一份能激发某种情绪的调色板列表，然后使用该调色板创建设计。 



<h2 id="seo-faq-pairs#what-are-prompt-engineering-techniques">什么是即时工程技术</h2>
提示工程是一个动态且不断演变的领域。需要通过语言技能和创造性表达来微调提示，并从生成式人工智能工具中获得所需的响应。

以下是一些提示工程师用来改进 AI 模型自然语言处理（NLP）任务的技术示例。



<h3 id="89b13e2f">思维链提示</h3>
思维链提示是一种将复杂的问题分解为模仿思路的较小的、合乎逻辑的部分的技术。这有助于模型通过一系列中间步骤解决问题，而不是直接回答问题。这增强了其推理能力。

您可以为复杂的任务展开多条思维链，然后选择最常得出的结论。如果展开后出现重大分歧，则可以通过咨询人员来纠正思维链。

例如，如果问题是“法国的首都是哪里？”，该模型可能会进行多次展开，得出诸如“巴黎”、“法国的首都是巴黎”和“巴黎是法国的首都”之类的答案。 由于所有推出都得出相同的结论，因此将选择“巴黎”作为最终答案。



<h3 id="5fc3bdbc">思维树提示</h3>
思维树技术是对思维链提示的泛化。前者会提示模型生成一个或多个可能的后续步骤。然后使用树搜索方法对每个可能的下一步运行模型。

例如，如果问题是“气候变化的影响是什么？”，该模型可能会首先生成可能的后续步骤，例如“列出环境影响 ”和“列出社会影响”。 然后，在后续步骤中详细说明其中每一项。



<h3 id="6de057a0">启发式提示</h3>
启发式提示类似于思想树提示。提示模型回答问题并提供解释，然后提示模式对部分解释内容再进行解释。不一致的解释树会被修剪或丢弃。这提高了复杂常识性推理的性能。

例如，如果问题是“为什么天空是蓝色的？”，模型可能会首先回答“人类眼中看到的天空是蓝色的，因为短波蓝光会被地球大气层中的气体和颗粒散射到各个方向。” 然后可能会扩展这种解释的部分内容，例如为什么蓝光比其他颜色散射得更多，以及地球大气层是由什么组成的。



<h3 id="c19d4585">基于复杂性的提示</h3>
这种提示工程技术涉及执行展开几条思维链。选择展开长度最长的思维链，然后选择最常得出的结论。

例如，如果问题是一个复杂的数学问题，则模型可能会展开多条思维链，每条都涉及多个计算步骤。考虑展开长度最长（在本例中，即计算步骤最多）的思维链。与其他思维链结论相同的思维链将被选为最终答案。



<h3 id="c41304ad">生成式知识提示</h3>
此技术需要提示模型首先生成补全提示所需的相关事实。然后继续补全提示。这通常会导致更高的完成质量，因为模型以相关事实为条件。

例如，假设用户提示模型写一篇关于森林砍伐影响的文章。该模型可能首先得出诸如“森林砍伐会导致气候变化”和“森林砍伐会导致生物多样性丧失”之类的事实。 然后将在文章中详细阐释每个要点。



<h3 id="a7b08cdd">由易至难提示</h3>
在这种提示工程技术中，会提示模型首先列出问题的子问题，然后按顺序逐一解决。这种方法确保可以借助先前子问题的答案解决后面的子问题。

例如，假设用户使用数学问题提示模型，例如“求解方程 2x + 3 = 11 中的 x”。 模型可能首先将子问题列为“从两边减去 3”和“除以 2”。然后会按顺序求解以获得最终答案。



<h3 id="505ada6b">自我完善提示</h3>
在这种技术中，提示模型解决问题，评论其解决方案，然后综合考虑问题、解决方案和评论以解决问题。问题解决过程会重复，直到达到预先确定的停止理由。例如，可能耗尽代币或时间，或者模型可能会输出停止令牌。

例如，假设用户提示模型“写一篇关于文学的短文”。 模型可能会起草一篇文章，评论文章缺乏具体的例子，然后重写文章以包括具体的例子。此过程将重复，直到短文被认为令人满意或满足停止条件。



<h3 id="a56624fa">定向刺激提示</h3>
这种提示工程技术包括提示或线索，例如所需的关键字，用于引导语言模型提供所需的输出。

例如，如果提示是写一首关于爱情的诗，那么提示工程师可能会创建包括“心”、“激情”和“永恒”在内的提示。 可以提示模型“写一首关于爱情的诗，里面有“心”、“激情”和“永恒”这几个词。 这将引导模型用这些关键字创作一首诗。



<h2 id="seo-faq-pairs#what-are-some-prompt-engineering-best-practices">有哪些提示工程最佳实践</h2>
良好的提示工程要求您传达有关上下文、范围和预期响应的指示。接下来，我们将分享一些最佳实践。



<h3 id="46eeb397">明确的提示</h3>
在提示中明确定义所需的响应，以避免 AI 误解。例如，如果您需要一份新颖的摘要，请明确说明您要的是摘要，而不是详细的分析。这有助于 AI 专注于您的请求，并提供与您的目标一致的响应。



<h3 id="bebbf96b">在提示中提供充分的背景信息</h3>
在提示中提供充分的背景信息，并在提示输入中包括输出要求，将其限制为特定的格式。例如，假设您想在表格中列出 20 世纪 90 年代最受欢迎的电影。要获得确切的结果，您应该明确说明要列出多少部电影，并要求格式化表格。



<h3 id="7b228095">平衡有针对性的信息和期望输出</h3>
平衡提示的简洁性和复杂性，以避免出现模糊、不相关或意想不到的答案。过于简单的提示可能缺乏上下文，而过于复杂的提示可能会让 AI 感到困惑。这对于 AI 可能不太熟悉的复杂主题或特定领域的语言尤其重要。相反，请使用简洁的语言并精简提示的长度，以使您的问题更容易理解。



<h3 id="dcbc31a4">对提示进行试验和完善</h3>
提示工程是一个迭代过程。必须尝试不同的想法并测试 AI 提示以查看结果。您可能需要多次尝试才能优化准确性和相关性。持续的测试和迭代可以精简提示，并帮助模型生成更好的输出。AI 输出信息的方式没有固定的规则，因此灵活性和适应性至关重要。



<h1 id="ad565e60">提示词工程的 16 种方式</h1>
<h2 id="a4d3b02a">概述</h2>
预训练、微调和提示词工程是大型语言模型（LLM）生成质量优化的三种关键手段，各自具有不同的特点和优势。

预训练是 LLM 发展的基石，通过在大规模无标注语料库上进行自监督学习，赋予模型通用的语言理解和生成能力。这种自然语言的通用知识为后续的微调和提示词工程奠定了坚实基础。

微调则是利用有标注的任务数据，对预训练模型进行进一步调整和优化，使其更好地适应特定的下游任务。微调的优势在于可以充分利用监督信号，提高模型在特定领域的生成质量。但同时也存在过度微调导致过拟合、灾难性遗忘等潜在风险。

与之不同，提示词工程无需对模型参数进行更新，而是通过设计合理的提示，激发预训练模型中蕴含的知识，从而在下游任务中获得良好的生成质量。这种方式更加高效灵活，避免了微调可能带来的问题。但提示词的设计质量对模型表现影响重大，需要更多研究来探索通用有效的提示设计范式。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023242-c7a236d8-3c37-49e9-a942-7df4b8bfb743.png) |
| --- |




接下来，本文将重点讨论提示词工程技术。文章将介绍提示词工程的基本原理、设计方法，以及在不同任务场景下的应用实践，旨在为读者提供全面的理解和借鉴。同时也会分析提示词工程当前面临的挑战和发展方向，为后续研究指明路径。



<h2 id="8c129ca3">提示词工程的分类</h2>
提示词工程的分类方法很多，本文将根据提示词工程技术发展演进路径，将类型分为：直接提示（Prompt）、链式提示（Chain）、图谱提示（Graph）、生成类提示（Generate）、集成式提示（Integrate） 五种。



<h3 id="28841c75">直接提示（Prompt）</h3>
这种直接的提示词的方式侧重点在于通过特定的指令设计，来提示模型产生更好的输出。主要方法包括：

Zero-shot（零次提示）、Few shots（少量提示）、Act 、ReAct 和 Directional Stimulus Prompting（方向性刺激提示）。



下面举几个例子，可以帮助大家加深这些方法差别的理解。

| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023095-887e27c6-e8af-47ca-9973-08780dca3f50.png) | 我该怎么表白？ |
| --- | --- |


| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023083-7413ae07-c310-49d6-9d3f-c5964f21cc75.png) | 这是几个例子，如何模仿这些例子对她表白？<br/><example><br/>…..<br/></emaple><br/><example><br/>…..<br/></emaple> |
| --- | --- |


| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023086-29855db2-2645-4eca-bc0c-37a42277576b.png) | 她喜欢哲学，我该怎么在表白的时候引入相关内容？ |
| --- | --- |




Zero Shot、Few Shots 和 Act 这三种偏向直接在问题中精心构造输入的内容。

| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023058-acac97d1-f5cb-4424-b746-b910646f862c.png) | 初始提示词：<br/>假如我们在圣诞节相遇，<br/>该如何把这个场景融入表白中？<br/>反应式提示：<br/>如果她接受了我的表白，<br/>下一步该怎么办？ |
| --- | --- |




而 ReAct 这种方式，更加关注外部的信息反馈，根据外部信息反馈后做归因然后再进行响应。

| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023521-136bc971-53bb-40bc-87dd-d2363996b56c.png) |
| --- |




Directional Stimulus Prompting，是指在提示词中加入一些提示，以限制在特定领域或限定的方向上生成的内容。请看如下例子：

| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023602-a1597542-0450-47a1-9eb7-a3c84206956b.png) |
| --- |


方向性刺激提示与标准提示的比较



<h3 id="d1cdcae2">链式提示（Chain）</h3>
| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023556-213329c7-a4d3-4444-b51d-eab662ec758a.png) |
| --- |


链式提示这种方式关注 LLM 的内部逻辑，比如思维链（Chain of Thought）、多模态思维链、思维树（Tree of Thought）。同时还关注在这个过程中的自洽（Self-consistent）和自我反思（Reflexion）。



在这个过程中，一般会将复杂问题进行拆解，分成多个步骤进行推理。这样做的好处是，可以让 LLM 在推理过程中更容易获得正确的答案。



例如，对于一些早期的大语言模型，我们输入“我有 23 个苹果，吃了 20 个后又买了 6 个，现在还有几个？”，大概率会给出错误答案。但是我们看在 Amazon Bedrock 上 Claude 3 Haiku 的响应，他将问题分解成了多个步骤，然后逐步推理获得了正确答案。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051023616-758d154b-1a6e-48ee-a821-297cd283b002.png) |
| --- |




这种技术的核心就是在提示过程中表现为顺序的，可解释的，能够清晰地看到思维推理的过程。



Reflexion 顾名思义，是大语言模型对自己生成内容进行反思的一种过程。这种自我反思，会记录本轮的问题和输出的答案并作为记忆（上下文），然后再用大语言模型验证生成内容是否符合“初心”。如果不匹配我们就会让这个过程重复“持续思考”，直到获得理想的答案。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024073-8515ead7-296a-4579-8671-8c8a1b1e0b9f.png) |
| --- |




Reflexion 流程示意图

下面看一个综合运用了多种链式范式综合案例。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024059-ba7636af-a8c9-4dfd-a2b6-30d8c5e1a050.png) |
| --- |


基于 Amazon Bedrock 上 LLM 的多 Agent 狼人杀游戏



这是一个基于多 Agent 的 AI 狼人杀游戏，在这个游戏中，多个游戏角色由 LLM 来扮演，主要通过 Claude 3 作为推理和发言的主模型，使用 Llama 3 8B Instruct 和 Mistral 7B Instruct 作为 Reflexion 和总结性文字的输出。不同游戏角色拥有不同的个性和记忆，角色会根据自己的记忆和游戏的流程不断去推理谁是地方阵营，并发动投票处决敌方。在每个轮次中，角色会对自己的发言进行自我反省，确定自己的发言是否对自己和己方阵营有利。这样做的好处就是可以避免角色出“昏招”。由于这个反省模型和发言模型不一样，这样也可以避开由于单一模型推理过程中造成的“偏见”的问题。在整个游戏过程中，每个角色都会根据外部的问题和事件，根据自己的独有记忆和共享记忆来对外部刺激作出响应。然后将“2 个大脑的声音”进行合理性验证，并得作出动作。这个游戏参考了“斯坦福小镇”的设计思路，对于制作开放式角色具有重要参考作用。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024126-67dc280b-1dcb-4eea-9f6f-944759294b70.png) |
| --- |


游戏主要流程设计



<h3 id="0a7a9820">谱图提示（Graph）</h3>
| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024148-603db23b-ab75-4518-ace8-9a5eb58bf8a2.png) |
| --- |




图谱提示和链条提示方式非常相似，都是关注大模型内部结构化的推理过程。但这个过程并不是线性的，而是假定训练过程中隐式地构建了网状或者是图形结构的知识图谱。在用户交互过程中，通过寻找不同知识的连接性和关联性，产生多个维度和更加复杂的非线性答案。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024262-e011fb11-4155-4f67-8892-550c2c8b4532.png) |
| --- |




在这个范式下我们一般会先通过实体的识别，先找出相关问题的出发点。而这个出发点可能不止一个，然后通过实体关系寻找可能的下一个相关节点的相关信息。然后重复这个过程直到在所有关系或指定的有限关系中找到相关内容，并对问题给出正确的解。这个范式适用于复杂数学问题、人物关系问题、犯罪线索发现等领域。



<h3 id="c627b984">生成类提示（Generate）</h3>
生成类提示，主要技术包括 Automatic Prompt  Engineer 和 Generate Knowledge Prompting。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024602-fcb60ce6-2e30-4cea-92bd-0d736b45d8b9.png) |
| --- |




+ Automatic Prompt Engineer 关注自动化。这个方法让指令生成问题被构建为自然语言合成问题，使用 LLMs 作为黑盒优化问题的解决方案来生成和搜索候选解。第一步选择一个语言模型用作推理，该模型接收输出数据以生成任务的指令候选项。这些候选解将指导搜索过程。使用大语言模型作为打分模型，然后根据计算的评估分数选择最合适的指令。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024795-8a33b386-d227-48b7-a988-4e9f56f8f551.png) |
| --- |




+ Generate Knowledge Prompting 关注内容生成。这种技术的特点是利用语言模型已有的知识进行与问题相关的知识片段的生成，以帮助模型做出更准确的预测。  


| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024927-319ada6e-b595-45d9-8038-f820fbac404e.png) |
| --- |




无论是哪种技术，都是利用 LLM 内部的知识来迭代补充知识的生成。下面举个例子大家可以对比着看。



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051024938-f84e7511-029d-4800-b76c-dbad02e8cefe.png) |
| --- |




使用某个大语言模型直接生成结果获得的错误例子

当然这个问题，现在使用更加强大的模型已经能直接获得正确答案。以下是使用 Amazon Bedrock 上 Claude 3 Haiku 的回答：



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051025038-226c8172-6524-4a29-b82f-4bf9734f8669.png) |
| --- |




正确响应

虽然这个例子中的问题，Claude 3 Haiku 已经能正确回答。但是在很多场景下我们还是可以通过 Generate Knowledge Prompting 技术来提高问题解答的正确率。下面我们看看这一切是如何发生的：



输入

| 问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？<br/>知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括 18 个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。解释和答案： |
| --- |




输出

| 不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。 |
| --- |


在实际实施的过程中，我们可能也会碰到一些输出不稳定的情况。具体情况需要根据业务来分析，可以考虑综合运用多种 PE 技术手段进行优化。



<h3 id="294ab2aa">集成式提示（Integrate）</h3>
| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051025049-1a57d1e6-6548-4db3-be5c-44cdd12de9eb.png) |
| --- |




集成式提示，包括检索增强生成（RAG）、自动推理、工具使用、程序辅助语言模型。这些方式的共性都是大语言模型与外部资源进行交互，从而实现复杂任务，提升答案质量。



下面介绍一个综合应用这些技术的例子，下图是在 2024 年亚马逊云科技中国峰会上展示的一个 Text2SQL 落地的案例，架构参考下图：



| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051025342-4fee15b0-91e7-4b7b-b703-0077a1f9f4c0.png) |
| --- |


Text2SQL 落地案例架构示意图



该解决方案基于自然语言的交互方式，通过意图识别过滤非法输入，用知识库中的查找相似问题并取回 SQL 语句（RAG），利用相似的 SQL 语句通过大语言模型生成目标 SQL 语句，根据 SQL 语句生成动态图表（PLA），还可以生成信息洞察。



<h1 id="OhBmH">小结</h1>
| ![](https://cdn.nlark.com/yuque/0/2025/png/45054063/1761051025475-c3cd10ee-c527-4e38-8afe-c30040ad68de.png) |
| --- |


本文一共介绍了 16 种提示词工程的相关技术，分别对应如何构建外部提示，利用内部知识逻辑或者借助外部数据信息，来引导模型产生更加准确的回答。

总的来说，提示词工程是一个充满活力和创新的领域，为大型语言模型的应用开辟了广阔的前景。通过不断探索和优化提示词的设计方法，我们能够最大限度地发挥模型的潜能，提高生成质量和任务适用性。未来，提示词工程必将与其他人工智能技术相互融合，为构建更加智能、高效和人性化的人机交互系统重要力量。



<h1 id="opFOC">参考链接</h1>
[Prompt Engineering Guide](https://www.promptingguide.ai/)

推荐文档：

[https://aws.amazon.com/cn/what-is/prompt-engineering/](https://aws.amazon.com/cn/what-is/prompt-engineering/)

[https://aws.amazon.com/cn/blogs/china/sixteen-ways-of-prompt-engineering/](https://aws.amazon.com/cn/blogs/china/sixteen-ways-of-prompt-engineering/)



推荐视频：[https://www.bilibili.com/video/BV1n9CwYoEro?t=613.1](https://www.bilibili.com/video/BV1n9CwYoEro?t=613.1)



